import requests
from bs4 import BeautifulSoup
import json
import praw
import csv
from itertools import zip_longest
from datetime import date

#webscrape of top 100 coins
cypto_price = requests.get('CRYPTOPRICE WEBSITE')
soup = BeautifulSoup(cypto_price.content, 'html.parser')

data = soup.find('script', id="__NEXT_DATA__", type="application/json")
coins = []

coin_data = json.loads(data.contents[0])
listings = coin_data['props']['initialState']['cryptocurrency']['listingLatest']['data']

for i in listings:
    coin_name = i['slug']
    if '-' in coin_name: # none of the subreddint names contain '-' they have no spaces between the words.
        tmp = coin_name.replace('-', '')
        coins.append(tmp)
    else:
        coins.append(i['slug'])

#  updated coin list as some coins names dont align with subreddit names. Will be using this list for the scrape
coin_list = ['bitcoin', 'ethereum', 'binancecoin', 'dogecoin', 'tether', 'cardano', 'xrp', 'internetcomputer', 'polkadot', 'bitcoincash', 'litecoin', 'uniswap', 'chainlink', 'stellar', 'usdcoin', 'vechain', 'solana', 'ethereumclassic', 'eos', 'theta', 'wrappedbitcoin', 'filecoin', 'tron', 'shibarmy', 'shibainucoin', 'binanceusd', 'monero', 'neo', 'Aave_Official', 'huobitoken', 'bitcoinsv', 'terraluna', 'polygon', 'ftxtoken', 'iota', 'klaytn', 'maker', 'pancakeswap', 'tezos', 'cosmos', 'multicollateraldai', 'avalanche', 'thorchain', 'cryptocomcoin', 'compound', 'bittorrent', 'algorand', 'kusama', 'zcash', 'dash', 'unussedleo', 'waves', 'nem', 'bitcoinbep2', 'elrondegld', 'decred', 'yearn_finance', 'chiliz', 'telcoin', 'zilliqa', 'okb', 'revain_org', 'qtum', 'synthetix_io', 'hedera', 'nexo', 'sushiswap', 'decentraland', 'terrausd', 'nearprotocol', 'holo', 'stacks', 'BitcoinGoldHQ', 'BasicAttentionToken', 'ontology', 'enjincoin', 'digibyte', 'thetafuel', 'thegraph', 'fantom', 'uma', 'celsius', 'siacoin', 'horizen', 'bancor', 'omise_go', '0xProject', 'icon', 'helium', 'ravencoin', 'PaxosStandardToken', 'swissborg', 'venus', 'trueusd', 'harmony', 'celo', 'nano', 'bitcoindiamond', 'ankr', 'bakerytoken', 'lisk']

#added lists in order to export to csv
sub_coin_list = []
subscriber_count_list = []
subscriber_count_active_list = []
dates = []

#  pulls subreddit subscriber count information for each coin in top 100 list.
def getUserCount(sub_name):
    r = praw.Reddit(client_id='',
                    client_secret='',
                    username='',
                    password='',
                    user_agent='')
    subreddit = r.subreddit(sub_name)
    sub_coin_list.append(sub_name)
    dates.append(str(date.today()))
    subscriber_count_list.append(subreddit.subscribers)
    subscriber_count_active_list.append(subreddit.accounts_active)

for obj in coin_list:
    try:
        getUserCount(obj)
    except:
        subscriber_count_list.append(0)
        subscriber_count_active_list.append(0)
        
#  exports data to csv
with open(str(date.today()) + '_subreddit_scrape.csv', 'w', newline='') as f:
    writer = csv.writer(f)
    writer.writerow(['Date', 'CoinName', 'TotalSubCount', 'ActiveSubCount'])
    writer.writerows(zip_longest(*[dates, sub_coin_list, subscriber_count_list, subscriber_count_active_list]))  

